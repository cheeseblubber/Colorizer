{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f4acade-5833-442f-99d9-56f74edf3c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/dl-env/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "model_index.json: 100%|██████████| 537/537 [00:00<00:00, 64.2kB/s]\n",
      "Fetching 13 files:   0%|          | 0/13 [00:00<?, ?it/s]\n",
      "model.safetensors:   0%|          | 0.00/1.36G [00:00<?, ?B/s]\u001b[A\n",
      "\n",
      "(…)ature_extractor/preprocessor_config.json:   0%|          | 0.00/342 [00:00<?, ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "tokenizer/tokenizer_config.json: 100%|██████████| 824/824 [00:00<00:00, 64.5kB/s][A\n",
      "(…)ature_extractor/preprocessor_config.json: 100%|██████████| 342/342 [00:00<00:00, 10.7kB/s]\n",
      "\n",
      "\n",
      "\n",
      "tokenizer/special_tokens_map.json:   0%|          | 0.00/460 [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "tokenizer/merges.txt:   0%|          | 0.00/525k [00:00<?, ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "scheduler/scheduler_config.json:   0%|          | 0.00/345 [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tokenizer/special_tokens_map.json: 100%|██████████| 460/460 [00:00<00:00, 7.67kB/s]\n",
      "scheduler/scheduler_config.json: 100%|██████████| 345/345 [00:00<00:00, 13.2kB/s]\n",
      "text_encoder/config.json: 100%|██████████| 633/633 [00:00<00:00, 39.7kB/s]\n",
      "tokenizer/merges.txt: 100%|██████████| 525k/525k [00:00<00:00, 10.0MB/s]\n",
      "\n",
      "\n",
      "tokenizer/vocab.json:   0%|          | 0.00/1.06M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:   0%|          | 0.00/3.46G [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "tokenizer/vocab.json: 100%|██████████| 1.06M/1.06M [00:00<00:00, 15.1MB/s]?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "unet/config.json: 100%|██████████| 909/909 [00:00<00:00, 414kB/s]\n",
      "\n",
      "\n",
      "vae/config.json: 100%|██████████| 611/611 [00:00<00:00, 274kB/s]\n",
      "\n",
      "model.safetensors:   1%|          | 10.5M/1.36G [00:00<00:45, 29.9MB/s]\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:   0%|          | 10.5M/3.46G [00:00<00:48, 71.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model.safetensors:   2%|▏         | 21.0M/1.36G [00:00<00:26, 50.3MB/s]\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:   1%|          | 31.5M/3.46G [00:00<00:26, 129MB/s] \u001b[A\u001b[A\u001b[A\n",
      "model.safetensors:   3%|▎         | 41.9M/1.36G [00:00<00:15, 84.1MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:   3%|▎         | 10.5M/335M [00:00<00:11, 28.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:   2%|▏         | 52.4M/3.46G [00:00<00:26, 129MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model.safetensors:   4%|▍         | 52.4M/1.36G [00:00<00:14, 89.0MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:   6%|▋         | 21.0M/335M [00:00<00:06, 47.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:   2%|▏         | 73.4M/3.46G [00:00<00:22, 148MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model.safetensors:   5%|▌         | 73.4M/1.36G [00:00<00:12, 107MB/s] \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  13%|█▎        | 41.9M/335M [00:00<00:03, 79.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:   3%|▎         | 94.4M/3.46G [00:00<00:23, 145MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model.safetensors:   7%|▋         | 94.4M/1.36G [00:01<00:11, 115MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  19%|█▉        | 62.9M/335M [00:00<00:02, 104MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:   3%|▎         | 115M/3.46G [00:00<00:24, 139MB/s] \u001b[A\u001b[A\u001b[A\n",
      "model.safetensors:   8%|▊         | 115M/1.36G [00:01<00:09, 126MB/s] \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  25%|██▌       | 83.9M/335M [00:00<00:02, 121MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:   4%|▍         | 136M/3.46G [00:00<00:23, 144MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  31%|███▏      | 105M/335M [00:01<00:01, 138MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model.safetensors:  10%|█         | 136M/1.36G [00:01<00:09, 125MB/s]\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:   5%|▍         | 157M/3.46G [00:01<00:24, 137MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  38%|███▊      | 126M/335M [00:01<00:01, 141MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model.safetensors:  12%|█▏        | 157M/1.36G [00:01<00:09, 124MB/s]\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:   5%|▌         | 178M/3.46G [00:01<00:25, 131MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  44%|████▍     | 147M/335M [00:01<00:01, 141MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:   6%|▌         | 199M/3.46G [00:01<00:22, 142MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model.safetensors:  13%|█▎        | 178M/1.36G [00:01<00:10, 116MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  50%|█████     | 168M/335M [00:01<00:01, 139MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model.safetensors:  15%|█▍        | 199M/1.36G [00:01<00:09, 118MB/s]\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:   6%|▋         | 220M/3.46G [00:01<00:25, 125MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  56%|█████▋    | 189M/335M [00:01<00:01, 132MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model.safetensors:  16%|█▌        | 220M/1.36G [00:02<00:08, 130MB/s]\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:   7%|▋         | 241M/3.46G [00:01<00:24, 129MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  63%|██████▎   | 210M/335M [00:01<00:00, 127MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model.safetensors:  18%|█▊        | 241M/1.36G [00:02<00:08, 133MB/s]\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:   8%|▊         | 262M/3.46G [00:01<00:24, 132MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  69%|██████▉   | 231M/335M [00:01<00:00, 137MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model.safetensors:  19%|█▉        | 262M/1.36G [00:02<00:08, 134MB/s]\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:   8%|▊         | 283M/3.46G [00:02<00:23, 137MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  75%|███████▌  | 252M/335M [00:02<00:00, 135MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model.safetensors:  21%|██        | 283M/1.36G [00:02<00:07, 147MB/s]\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:   9%|▉         | 304M/3.46G [00:02<00:24, 128MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  81%|████████▏ | 273M/335M [00:02<00:00, 129MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model.safetensors:  22%|██▏       | 304M/1.36G [00:02<00:07, 145MB/s]\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:   9%|▉         | 325M/3.46G [00:02<00:22, 137MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  88%|████████▊ | 294M/335M [00:02<00:00, 141MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model.safetensors:  24%|██▍       | 325M/1.36G [00:02<00:06, 151MB/s]\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  10%|▉         | 346M/3.46G [00:02<00:22, 139MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  94%|█████████▍| 315M/335M [00:02<00:00, 140MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model.safetensors:  25%|██▌       | 346M/1.36G [00:02<00:07, 139MB/s]\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  11%|█         | 367M/3.46G [00:02<00:23, 134MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model.safetensors:  27%|██▋       | 367M/1.36G [00:03<00:06, 143MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors: 100%|██████████| 335M/335M [00:02<00:00, 120MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  11%|█         | 388M/3.46G [00:02<00:22, 138MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model.safetensors:  28%|██▊       | 388M/1.36G [00:03<00:06, 153MB/s]\u001b[A\n",
      "model.safetensors:  30%|███       | 409M/1.36G [00:03<00:05, 164MB/s]\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  12%|█▏        | 409M/3.46G [00:03<00:21, 139MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model.safetensors:  32%|███▏      | 430M/1.36G [00:03<00:05, 169MB/s]\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  12%|█▏        | 430M/3.46G [00:03<00:20, 145MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model.safetensors:  33%|███▎      | 451M/1.36G [00:03<00:05, 172MB/s]\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  13%|█▎        | 461M/3.46G [00:03<00:18, 160MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model.safetensors:  35%|███▍      | 472M/1.36G [00:03<00:05, 172MB/s]\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  14%|█▍        | 482M/3.46G [00:03<00:17, 170MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model.safetensors:  36%|███▌      | 493M/1.36G [00:03<00:04, 181MB/s]\u001b[A\n",
      "model.safetensors:  38%|███▊      | 514M/1.36G [00:03<00:04, 186MB/s]\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  15%|█▍        | 503M/3.46G [00:03<00:18, 159MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model.safetensors:  39%|███▉      | 535M/1.36G [00:03<00:04, 189MB/s]\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  15%|█▌        | 524M/3.46G [00:03<00:17, 164MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model.safetensors:  41%|████      | 556M/1.36G [00:04<00:04, 187MB/s]\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  16%|█▌        | 545M/3.46G [00:03<00:19, 152MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model.safetensors:  42%|████▏     | 577M/1.36G [00:04<00:04, 184MB/s]\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  16%|█▋        | 566M/3.46G [00:03<00:18, 154MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model.safetensors:  44%|████▍     | 598M/1.36G [00:04<00:04, 180MB/s]\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  17%|█▋        | 587M/3.46G [00:04<00:17, 164MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model.safetensors:  45%|████▌     | 619M/1.36G [00:04<00:04, 181MB/s]\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  18%|█▊        | 608M/3.46G [00:04<00:17, 167MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model.safetensors:  47%|████▋     | 640M/1.36G [00:04<00:03, 181MB/s]\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  18%|█▊        | 629M/3.46G [00:04<00:16, 172MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model.safetensors:  49%|████▊     | 661M/1.36G [00:04<00:03, 183MB/s]\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  19%|█▉        | 661M/3.46G [00:04<00:15, 182MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model.safetensors:  51%|█████     | 692M/1.36G [00:04<00:03, 194MB/s]\u001b[A\n",
      "model.safetensors:  52%|█████▏    | 713M/1.36G [00:04<00:03, 196MB/s]\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  20%|█▉        | 692M/3.46G [00:04<00:14, 186MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model.safetensors:  54%|█████▍    | 734M/1.36G [00:04<00:03, 196MB/s]\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  21%|██        | 713M/3.46G [00:04<00:14, 190MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model.safetensors:  56%|█████▌    | 765M/1.36G [00:05<00:02, 207MB/s]\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  21%|██        | 734M/3.46G [00:04<00:14, 183MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  22%|██▏       | 755M/3.46G [00:04<00:14, 184MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model.safetensors:  58%|█████▊    | 786M/1.36G [00:05<00:03, 177MB/s]\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  22%|██▏       | 776M/3.46G [00:05<00:14, 184MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model.safetensors:  59%|█████▉    | 807M/1.36G [00:05<00:03, 181MB/s]\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  23%|██▎       | 797M/3.46G [00:05<00:14, 179MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model.safetensors:  61%|██████    | 828M/1.36G [00:05<00:03, 176MB/s]\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  24%|██▎       | 818M/3.46G [00:05<00:15, 170MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model.safetensors:  62%|██████▏   | 849M/1.36G [00:05<00:03, 163MB/s]\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  24%|██▍       | 839M/3.46G [00:05<00:14, 175MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model.safetensors:  65%|██████▍   | 881M/1.36G [00:05<00:02, 176MB/s]\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  25%|██▍       | 860M/3.46G [00:05<00:14, 181MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model.safetensors:  66%|██████▌   | 902M/1.36G [00:05<00:02, 182MB/s]\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  25%|██▌       | 881M/3.46G [00:05<00:14, 175MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model.safetensors:  68%|██████▊   | 923M/1.36G [00:06<00:02, 182MB/s]\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  26%|██▌       | 902M/3.46G [00:05<00:14, 181MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model.safetensors:  69%|██████▉   | 944M/1.36G [00:06<00:02, 178MB/s]\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  27%|██▋       | 923M/3.46G [00:05<00:14, 180MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model.safetensors:  71%|███████   | 965M/1.36G [00:06<00:02, 181MB/s]\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  27%|██▋       | 944M/3.46G [00:06<00:14, 180MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model.safetensors:  72%|███████▏  | 986M/1.36G [00:06<00:02, 186MB/s]\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  28%|██▊       | 965M/3.46G [00:06<00:13, 184MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model.safetensors:  75%|███████▍  | 1.02G/1.36G [00:06<00:01, 196MB/s]\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  28%|██▊       | 986M/3.46G [00:06<00:14, 173MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model.safetensors:  76%|███████▌  | 1.04G/1.36G [00:06<00:01, 195MB/s]\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  29%|██▉       | 1.01G/3.46G [00:06<00:14, 170MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model.safetensors:  78%|███████▊  | 1.06G/1.36G [00:06<00:01, 186MB/s]\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  30%|██▉       | 1.03G/3.46G [00:06<00:13, 176MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model.safetensors:  79%|███████▉  | 1.08G/1.36G [00:06<00:01, 177MB/s]\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  30%|███       | 1.05G/3.46G [00:06<00:14, 167MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model.safetensors:  81%|████████  | 1.10G/1.36G [00:06<00:01, 182MB/s]\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  31%|███       | 1.07G/3.46G [00:06<00:14, 169MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model.safetensors:  82%|████████▏ | 1.12G/1.36G [00:07<00:01, 186MB/s]\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  31%|███▏      | 1.09G/3.46G [00:06<00:13, 179MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model.safetensors:  85%|████████▍ | 1.15G/1.36G [00:07<00:01, 198MB/s]\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  32%|███▏      | 1.11G/3.46G [00:07<00:13, 175MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model.safetensors:  86%|████████▋ | 1.17G/1.36G [00:07<00:00, 198MB/s]\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  33%|███▎      | 1.13G/3.46G [00:07<00:13, 176MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model.safetensors:  88%|████████▊ | 1.20G/1.36G [00:07<00:00, 196MB/s]\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  33%|███▎      | 1.15G/3.46G [00:07<00:12, 180MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model.safetensors:  89%|████████▉ | 1.22G/1.36G [00:07<00:00, 187MB/s]\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  34%|███▍      | 1.17G/3.46G [00:07<00:12, 178MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model.safetensors:  91%|█████████ | 1.24G/1.36G [00:07<00:00, 188MB/s]\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  35%|███▍      | 1.20G/3.46G [00:07<00:14, 159MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model.safetensors:  92%|█████████▏| 1.26G/1.36G [00:07<00:00, 187MB/s]\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  35%|███▌      | 1.22G/3.46G [00:07<00:13, 165MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model.safetensors:  94%|█████████▍| 1.28G/1.36G [00:07<00:00, 186MB/s]\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  36%|███▌      | 1.24G/3.46G [00:07<00:13, 169MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model.safetensors:  95%|█████████▌| 1.30G/1.36G [00:08<00:00, 171MB/s]\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  36%|███▋      | 1.26G/3.46G [00:07<00:12, 176MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model.safetensors:  97%|█████████▋| 1.32G/1.36G [00:08<00:00, 176MB/s]\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  37%|███▋      | 1.29G/3.46G [00:08<00:11, 188MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model.safetensors:  99%|█████████▊| 1.34G/1.36G [00:08<00:00, 178MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors: 100%|██████████| 1.36G/1.36G [00:08<00:00, 162MB/s]08<00:11, 188MB/s]\u001b[A\u001b[A\u001b[A\n",
      "Fetching 13 files:  38%|███▊      | 5/13 [00:08<00:14,  1.81s/it]\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  38%|███▊      | 1.33G/3.46G [00:08<00:11, 193MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  39%|███▉      | 1.36G/3.46G [00:08<00:09, 210MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  40%|████      | 1.39G/3.46G [00:08<00:08, 233MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  41%|████      | 1.43G/3.46G [00:08<00:08, 248MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  42%|████▏     | 1.46G/3.46G [00:08<00:07, 262MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  43%|████▎     | 1.49G/3.46G [00:08<00:07, 258MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  44%|████▍     | 1.52G/3.46G [00:08<00:07, 262MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  45%|████▍     | 1.55G/3.46G [00:09<00:07, 269MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  46%|████▌     | 1.58G/3.46G [00:09<00:06, 276MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  47%|████▋     | 1.61G/3.46G [00:09<00:06, 273MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  48%|████▊     | 1.65G/3.46G [00:09<00:06, 269MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  48%|████▊     | 1.68G/3.46G [00:09<00:06, 278MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  49%|████▉     | 1.71G/3.46G [00:09<00:06, 269MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  50%|█████     | 1.74G/3.46G [00:09<00:06, 272MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  51%|█████     | 1.77G/3.46G [00:09<00:06, 270MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  52%|█████▏    | 1.80G/3.46G [00:09<00:06, 275MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  53%|█████▎    | 1.84G/3.46G [00:10<00:06, 266MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  54%|█████▍    | 1.87G/3.46G [00:10<00:06, 238MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  55%|█████▍    | 1.90G/3.46G [00:10<00:06, 250MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  56%|█████▌    | 1.93G/3.46G [00:10<00:05, 259MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  57%|█████▋    | 1.96G/3.46G [00:10<00:05, 268MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  58%|█████▊    | 1.99G/3.46G [00:10<00:05, 274MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  58%|█████▊    | 2.02G/3.46G [00:10<00:05, 279MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  59%|█████▉    | 2.06G/3.46G [00:10<00:05, 276MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  60%|██████    | 2.09G/3.46G [00:11<00:05, 266MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  61%|██████    | 2.12G/3.46G [00:11<00:04, 272MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  62%|██████▏   | 2.15G/3.46G [00:11<00:04, 263MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  63%|██████▎   | 2.18G/3.46G [00:11<00:04, 259MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  64%|██████▍   | 2.21G/3.46G [00:11<00:04, 265MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  65%|██████▍   | 2.24G/3.46G [00:11<00:04, 270MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  66%|██████▌   | 2.28G/3.46G [00:11<00:04, 273MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  67%|██████▋   | 2.31G/3.46G [00:11<00:04, 279MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  68%|██████▊   | 2.34G/3.46G [00:11<00:03, 284MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  68%|██████▊   | 2.37G/3.46G [00:12<00:03, 286MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  69%|██████▉   | 2.40G/3.46G [00:12<00:03, 289MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  70%|███████   | 2.43G/3.46G [00:12<00:03, 289MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  71%|███████   | 2.46G/3.46G [00:12<00:03, 288MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  72%|███████▏  | 2.50G/3.46G [00:12<00:03, 288MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  73%|███████▎  | 2.53G/3.46G [00:12<00:03, 280MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  74%|███████▍  | 2.56G/3.46G [00:12<00:03, 282MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  75%|███████▍  | 2.59G/3.46G [00:12<00:03, 274MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  76%|███████▌  | 2.62G/3.46G [00:13<00:04, 172MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  77%|███████▋  | 2.65G/3.46G [00:13<00:04, 188MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  77%|███████▋  | 2.68G/3.46G [00:13<00:03, 203MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  78%|███████▊  | 2.72G/3.46G [00:13<00:03, 218MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  79%|███████▉  | 2.75G/3.46G [00:13<00:03, 226MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  80%|████████  | 2.78G/3.46G [00:13<00:02, 239MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  81%|████████  | 2.81G/3.46G [00:13<00:02, 251MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  82%|████████▏ | 2.84G/3.46G [00:14<00:02, 265MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  83%|████████▎ | 2.87G/3.46G [00:14<00:02, 272MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  84%|████████▍ | 2.90G/3.46G [00:14<00:02, 278MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  85%|████████▍ | 2.94G/3.46G [00:14<00:01, 272MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  86%|████████▌ | 2.97G/3.46G [00:14<00:01, 278MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  87%|████████▋ | 3.00G/3.46G [00:14<00:01, 282MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  87%|████████▋ | 3.03G/3.46G [00:14<00:01, 278MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  88%|████████▊ | 3.06G/3.46G [00:14<00:01, 277MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  89%|████████▉ | 3.09G/3.46G [00:14<00:01, 273MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  90%|█████████ | 3.12G/3.46G [00:15<00:01, 244MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  91%|█████████ | 3.16G/3.46G [00:15<00:01, 241MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  92%|█████████▏| 3.19G/3.46G [00:15<00:01, 243MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  93%|█████████▎| 3.22G/3.46G [00:15<00:01, 243MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  94%|█████████▍| 3.25G/3.46G [00:15<00:00, 253MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  95%|█████████▍| 3.28G/3.46G [00:15<00:00, 260MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  96%|█████████▌| 3.31G/3.46G [00:15<00:00, 266MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  97%|█████████▋| 3.34G/3.46G [00:15<00:00, 266MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  97%|█████████▋| 3.38G/3.46G [00:16<00:00, 274MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors:  98%|█████████▊| 3.41G/3.46G [00:16<00:00, 263MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.safetensors: 100%|██████████| 3.46G/3.46G [00:16<00:00, 211MB/s]\u001b[A\u001b[A\u001b[A\n",
      "Fetching 13 files: 100%|██████████| 13/13 [00:16<00:00,  1.29s/it]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from diffusers import StableDiffusionPipeline\n",
    "\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\"stabilityai/stable-diffusion-2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06b58be2-5801-48fb-90ca-83776ffde1ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m      \u001b[0mpipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_extractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_processing_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBatchFeature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mType:\u001b[0m           CLIPImageProcessor\n",
       "\u001b[0;31mString form:\u001b[0m   \n",
       "CLIPImageProcessor {\n",
       "  \"_valid_processor_keys\": [\n",
       "    \"images\",\n",
       "    \"do_resize\",\n",
       "    \"size\",\n",
       "    \"resample\",\n",
       "    \"do_center_crop\",\n",
       "    \"crop_size\",\n",
       "    \"do_rescale\",\n",
       "    \"rescale_factor\",\n",
       "    \"do_normalize\",\n",
       "    \"image_mean\",\n",
       "    \"image_std\",\n",
       "    \"do_convert_rgb\",\n",
       "    \"return_tensors\",\n",
       "    \"data_format\",\n",
       "    \"input_data_format\"\n",
       "  ],\n",
       "  \"crop_size\": {\n",
       "    \"height\": 224,\n",
       "    \"width\": 224\n",
       "  },\n",
       "  \"do_center_crop\": true,\n",
       "  \"do_convert_rgb\": true,\n",
       "  \"do_normalize\": true,\n",
       "  \"do_rescale\": true,\n",
       "  \"do_resize\": true,\n",
       "  \"image_mean\": [\n",
       "    0.48145466,\n",
       "    0.4578275,\n",
       "    0.40821073\n",
       "  ],\n",
       "  \"image_processor_type\": \"CLIPImageProcessor\",\n",
       "  \"image_std\": [\n",
       "    0.26862954,\n",
       "    0.26130258,\n",
       "    0.27577711\n",
       "  ],\n",
       "  \"resample\": 3,\n",
       "  \"rescale_factor\": 0.00392156862745098,\n",
       "  \"size\": {\n",
       "    \"shortest_edge\": 224\n",
       "  }\n",
       "}\n",
       "\u001b[0;31mFile:\u001b[0m           ~/miniconda3/envs/dl-env/lib/python3.8/site-packages/transformers/models/clip/image_processing_clip.py\n",
       "\u001b[0;31mSource:\u001b[0m        \n",
       "\u001b[0;32mclass\u001b[0m \u001b[0mCLIPImageProcessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseImageProcessor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34mr\"\"\"\u001b[0m\n",
       "\u001b[0;34m    Constructs a CLIP image processor.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Args:\u001b[0m\n",
       "\u001b[0;34m        do_resize (`bool`, *optional*, defaults to `True`):\u001b[0m\n",
       "\u001b[0;34m            Whether to resize the image's (height, width) dimensions to the specified `size`. Can be overridden by\u001b[0m\n",
       "\u001b[0;34m            `do_resize` in the `preprocess` method.\u001b[0m\n",
       "\u001b[0;34m        size (`Dict[str, int]` *optional*, defaults to `{\"shortest_edge\": 224}`):\u001b[0m\n",
       "\u001b[0;34m            Size of the image after resizing. The shortest edge of the image is resized to size[\"shortest_edge\"], with\u001b[0m\n",
       "\u001b[0;34m            the longest edge resized to keep the input aspect ratio. Can be overridden by `size` in the `preprocess`\u001b[0m\n",
       "\u001b[0;34m            method.\u001b[0m\n",
       "\u001b[0;34m        resample (`PILImageResampling`, *optional*, defaults to `Resampling.BICUBIC`):\u001b[0m\n",
       "\u001b[0;34m            Resampling filter to use if resizing the image. Can be overridden by `resample` in the `preprocess` method.\u001b[0m\n",
       "\u001b[0;34m        do_center_crop (`bool`, *optional*, defaults to `True`):\u001b[0m\n",
       "\u001b[0;34m            Whether to center crop the image to the specified `crop_size`. Can be overridden by `do_center_crop` in the\u001b[0m\n",
       "\u001b[0;34m            `preprocess` method.\u001b[0m\n",
       "\u001b[0;34m        crop_size (`Dict[str, int]` *optional*, defaults to 224):\u001b[0m\n",
       "\u001b[0;34m            Size of the output image after applying `center_crop`. Can be overridden by `crop_size` in the `preprocess`\u001b[0m\n",
       "\u001b[0;34m            method.\u001b[0m\n",
       "\u001b[0;34m        do_rescale (`bool`, *optional*, defaults to `True`):\u001b[0m\n",
       "\u001b[0;34m            Whether to rescale the image by the specified scale `rescale_factor`. Can be overridden by `do_rescale` in\u001b[0m\n",
       "\u001b[0;34m            the `preprocess` method.\u001b[0m\n",
       "\u001b[0;34m        rescale_factor (`int` or `float`, *optional*, defaults to `1/255`):\u001b[0m\n",
       "\u001b[0;34m            Scale factor to use if rescaling the image. Can be overridden by `rescale_factor` in the `preprocess`\u001b[0m\n",
       "\u001b[0;34m            method.\u001b[0m\n",
       "\u001b[0;34m        do_normalize (`bool`, *optional*, defaults to `True`):\u001b[0m\n",
       "\u001b[0;34m            Whether to normalize the image. Can be overridden by `do_normalize` in the `preprocess` method.\u001b[0m\n",
       "\u001b[0;34m        image_mean (`float` or `List[float]`, *optional*, defaults to `[0.48145466, 0.4578275, 0.40821073]`):\u001b[0m\n",
       "\u001b[0;34m            Mean to use if normalizing the image. This is a float or list of floats the length of the number of\u001b[0m\n",
       "\u001b[0;34m            channels in the image. Can be overridden by the `image_mean` parameter in the `preprocess` method.\u001b[0m\n",
       "\u001b[0;34m        image_std (`float` or `List[float]`, *optional*, defaults to `[0.26862954, 0.26130258, 0.27577711]`):\u001b[0m\n",
       "\u001b[0;34m            Standard deviation to use if normalizing the image. This is a float or list of floats the length of the\u001b[0m\n",
       "\u001b[0;34m            number of channels in the image. Can be overridden by the `image_std` parameter in the `preprocess` method.\u001b[0m\n",
       "\u001b[0;34m            Can be overridden by the `image_std` parameter in the `preprocess` method.\u001b[0m\n",
       "\u001b[0;34m        do_convert_rgb (`bool`, *optional*, defaults to `True`):\u001b[0m\n",
       "\u001b[0;34m            Whether to convert the image to RGB.\u001b[0m\n",
       "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmodel_input_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"pixel_values\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mdo_resize\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0msize\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mresample\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mPILImageResampling\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPILImageResampling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBICUBIC\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mdo_center_crop\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mcrop_size\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mdo_rescale\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mrescale_factor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mdo_normalize\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mimage_mean\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mimage_std\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mdo_convert_rgb\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msize\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"shortest_edge\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_size_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_to_square\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mcrop_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrop_size\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcrop_size\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"height\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"width\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mcrop_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_size_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcrop_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_to_square\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"crop_size\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_resize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdo_resize\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_center_crop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdo_center_crop\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrop_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrop_size\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_rescale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdo_rescale\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrescale_factor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrescale_factor\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_normalize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdo_normalize\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_mean\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mimage_mean\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mOPENAI_CLIP_MEAN\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_std\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_std\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mimage_std\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mOPENAI_CLIP_STD\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_convert_rgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdo_convert_rgb\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_valid_processor_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m\"images\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m\"do_resize\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m\"size\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m\"resample\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m\"do_center_crop\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m\"crop_size\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m\"do_rescale\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m\"rescale_factor\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m\"do_normalize\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m\"image_mean\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m\"image_std\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m\"do_convert_rgb\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m\"return_tensors\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m\"data_format\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m\"input_data_format\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# for backwards compatibility of KOSMOS-2\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;34m\"use_square_size\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"height\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shortest_edge\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"width\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shortest_edge\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mimage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0msize\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mresample\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mPILImageResampling\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPILImageResampling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBICUBIC\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mdata_format\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mChannelDimension\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0minput_data_format\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mChannelDimension\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"\u001b[0m\n",
       "\u001b[0;34m        Resize an image. The shortest edge of the image is resized to size[\"shortest_edge\"], with the longest edge\u001b[0m\n",
       "\u001b[0;34m        resized to keep the input aspect ratio.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Args:\u001b[0m\n",
       "\u001b[0;34m            image (`np.ndarray`):\u001b[0m\n",
       "\u001b[0;34m                Image to resize.\u001b[0m\n",
       "\u001b[0;34m            size (`Dict[str, int]`):\u001b[0m\n",
       "\u001b[0;34m                Size of the output image.\u001b[0m\n",
       "\u001b[0;34m            resample (`PILImageResampling`, *optional*, defaults to `PILImageResampling.BICUBIC`):\u001b[0m\n",
       "\u001b[0;34m                Resampling filter to use when resiizing the image.\u001b[0m\n",
       "\u001b[0;34m            data_format (`str` or `ChannelDimension`, *optional*):\u001b[0m\n",
       "\u001b[0;34m                The channel dimension format of the image. If not provided, it will be the same as the input image.\u001b[0m\n",
       "\u001b[0;34m            input_data_format (`ChannelDimension` or `str`, *optional*):\u001b[0m\n",
       "\u001b[0;34m                The channel dimension format of the input image. If not provided, it will be inferred.\u001b[0m\n",
       "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mdefault_to_square\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;34m\"shortest_edge\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shortest_edge\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mdefault_to_square\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32melif\u001b[0m \u001b[0;34m\"height\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msize\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"width\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"height\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"width\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Size must contain either 'shortest_edge' or 'height' and 'width'.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0moutput_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_resize_output_image_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mdefault_to_square\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_to_square\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0minput_data_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_data_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mresample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0minput_data_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_data_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mimages\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mImageInput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mdo_resize\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0msize\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mresample\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mPILImageResampling\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mdo_center_crop\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mcrop_size\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mdo_rescale\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mrescale_factor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mdo_normalize\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mimage_mean\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mimage_std\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mdo_convert_rgb\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensorType\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mdata_format\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mChannelDimension\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mChannelDimension\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFIRST\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0minput_data_format\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mChannelDimension\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mPIL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"\u001b[0m\n",
       "\u001b[0;34m        Preprocess an image or batch of images.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Args:\u001b[0m\n",
       "\u001b[0;34m            images (`ImageInput`):\u001b[0m\n",
       "\u001b[0;34m                Image to preprocess. Expects a single or batch of images with pixel values ranging from 0 to 255. If\u001b[0m\n",
       "\u001b[0;34m                passing in images with pixel values between 0 and 1, set `do_rescale=False`.\u001b[0m\n",
       "\u001b[0;34m            do_resize (`bool`, *optional*, defaults to `self.do_resize`):\u001b[0m\n",
       "\u001b[0;34m                Whether to resize the image.\u001b[0m\n",
       "\u001b[0;34m            size (`Dict[str, int]`, *optional*, defaults to `self.size`):\u001b[0m\n",
       "\u001b[0;34m                Size of the image after resizing. Shortest edge of the image is resized to size[\"shortest_edge\"], with\u001b[0m\n",
       "\u001b[0;34m                the longest edge resized to keep the input aspect ratio.\u001b[0m\n",
       "\u001b[0;34m            resample (`int`, *optional*, defaults to `self.resample`):\u001b[0m\n",
       "\u001b[0;34m                Resampling filter to use if resizing the image. This can be one of the enum `PILImageResampling`. Only\u001b[0m\n",
       "\u001b[0;34m                has an effect if `do_resize` is set to `True`.\u001b[0m\n",
       "\u001b[0;34m            do_center_crop (`bool`, *optional*, defaults to `self.do_center_crop`):\u001b[0m\n",
       "\u001b[0;34m                Whether to center crop the image.\u001b[0m\n",
       "\u001b[0;34m            crop_size (`Dict[str, int]`, *optional*, defaults to `self.crop_size`):\u001b[0m\n",
       "\u001b[0;34m                Size of the center crop. Only has an effect if `do_center_crop` is set to `True`.\u001b[0m\n",
       "\u001b[0;34m            do_rescale (`bool`, *optional*, defaults to `self.do_rescale`):\u001b[0m\n",
       "\u001b[0;34m                Whether to rescale the image.\u001b[0m\n",
       "\u001b[0;34m            rescale_factor (`float`, *optional*, defaults to `self.rescale_factor`):\u001b[0m\n",
       "\u001b[0;34m                Rescale factor to rescale the image by if `do_rescale` is set to `True`.\u001b[0m\n",
       "\u001b[0;34m            do_normalize (`bool`, *optional*, defaults to `self.do_normalize`):\u001b[0m\n",
       "\u001b[0;34m                Whether to normalize the image.\u001b[0m\n",
       "\u001b[0;34m            image_mean (`float` or `List[float]`, *optional*, defaults to `self.image_mean`):\u001b[0m\n",
       "\u001b[0;34m                Image mean to use for normalization. Only has an effect if `do_normalize` is set to `True`.\u001b[0m\n",
       "\u001b[0;34m            image_std (`float` or `List[float]`, *optional*, defaults to `self.image_std`):\u001b[0m\n",
       "\u001b[0;34m                Image standard deviation to use for normalization. Only has an effect if `do_normalize` is set to\u001b[0m\n",
       "\u001b[0;34m                `True`.\u001b[0m\n",
       "\u001b[0;34m            do_convert_rgb (`bool`, *optional*, defaults to `self.do_convert_rgb`):\u001b[0m\n",
       "\u001b[0;34m                Whether to convert the image to RGB.\u001b[0m\n",
       "\u001b[0;34m            return_tensors (`str` or `TensorType`, *optional*):\u001b[0m\n",
       "\u001b[0;34m                The type of tensors to return. Can be one of:\u001b[0m\n",
       "\u001b[0;34m                - Unset: Return a list of `np.ndarray`.\u001b[0m\n",
       "\u001b[0;34m                - `TensorType.TENSORFLOW` or `'tf'`: Return a batch of type `tf.Tensor`.\u001b[0m\n",
       "\u001b[0;34m                - `TensorType.PYTORCH` or `'pt'`: Return a batch of type `torch.Tensor`.\u001b[0m\n",
       "\u001b[0;34m                - `TensorType.NUMPY` or `'np'`: Return a batch of type `np.ndarray`.\u001b[0m\n",
       "\u001b[0;34m                - `TensorType.JAX` or `'jax'`: Return a batch of type `jax.numpy.ndarray`.\u001b[0m\n",
       "\u001b[0;34m            data_format (`ChannelDimension` or `str`, *optional*, defaults to `ChannelDimension.FIRST`):\u001b[0m\n",
       "\u001b[0;34m                The channel dimension format for the output image. Can be one of:\u001b[0m\n",
       "\u001b[0;34m                - `\"channels_first\"` or `ChannelDimension.FIRST`: image in (num_channels, height, width) format.\u001b[0m\n",
       "\u001b[0;34m                - `\"channels_last\"` or `ChannelDimension.LAST`: image in (height, width, num_channels) format.\u001b[0m\n",
       "\u001b[0;34m                - Unset: Use the channel dimension format of the input image.\u001b[0m\n",
       "\u001b[0;34m            input_data_format (`ChannelDimension` or `str`, *optional*):\u001b[0m\n",
       "\u001b[0;34m                The channel dimension format for the input image. If unset, the channel dimension format is inferred\u001b[0m\n",
       "\u001b[0;34m                from the input image. Can be one of:\u001b[0m\n",
       "\u001b[0;34m                - `\"channels_first\"` or `ChannelDimension.FIRST`: image in (num_channels, height, width) format.\u001b[0m\n",
       "\u001b[0;34m                - `\"channels_last\"` or `ChannelDimension.LAST`: image in (height, width, num_channels) format.\u001b[0m\n",
       "\u001b[0;34m                - `\"none\"` or `ChannelDimension.NONE`: image in (height, width) format.\u001b[0m\n",
       "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mdo_resize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdo_resize\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdo_resize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_resize\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msize\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_size_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"size\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_to_square\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mresample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresample\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mresample\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresample\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mdo_center_crop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdo_center_crop\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdo_center_crop\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_center_crop\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mcrop_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrop_size\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcrop_size\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrop_size\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mcrop_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_size_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcrop_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"crop_size\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_to_square\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mdo_rescale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdo_rescale\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdo_rescale\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_rescale\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mrescale_factor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrescale_factor\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrescale_factor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrescale_factor\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mdo_normalize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdo_normalize\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdo_normalize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_normalize\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mimage_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_mean\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mimage_mean\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_mean\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mimage_std\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_std\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mimage_std\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_std\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mdo_convert_rgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdo_convert_rgb\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdo_convert_rgb\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_convert_rgb\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mvalidate_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcaptured_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_processor_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_valid_processor_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_list_of_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvalid_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;34m\"Invalid image type. Must be of type PIL.Image.Image, numpy.ndarray, \"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;34m\"torch.Tensor, tf.Tensor or jax.ndarray.\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mvalidate_preprocess_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mdo_rescale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdo_rescale\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mrescale_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrescale_factor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mdo_normalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdo_normalize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mimage_mean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage_mean\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mimage_std\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage_std\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mdo_center_crop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdo_center_crop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mcrop_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcrop_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mdo_resize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdo_resize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mresample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mdo_convert_rgb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mconvert_to_rgb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# All transformations expect numpy arrays.\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mto_numpy_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mis_scaled_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdo_rescale\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;34m\"It looks like you are trying to rescale already rescaled images. If the input\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;34m\" images have pixel values between 0 and 1, set `do_rescale=False` to avoid rescaling them again.\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0minput_data_format\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;31m# We assume that all images have the same channel dimension format.\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0minput_data_format\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfer_channel_dimension_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mdo_resize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_data_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_data_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mdo_center_crop\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcenter_crop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcrop_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_data_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_data_format\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mdo_rescale\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrescale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrescale_factor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_data_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_data_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mdo_normalize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage_std\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_data_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_data_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mto_channel_dimension_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_channel_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_data_format\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"pixel_values\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mBatchFeature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mInit docstring:\u001b[0m Set elements of `kwargs` as attributes.\n",
       "\u001b[0;31mCall docstring:\u001b[0m Preprocess an image or a batch of images."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "??pipe.feature_extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "456443c8-7aed-4fdb-aa2d-cc1a9d4ce9a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m      \u001b[0mpipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mType:\u001b[0m           UNet2DConditionModel\n",
       "\u001b[0;31mString form:\u001b[0m   \n",
       "UNet2DConditionModel(\n",
       "  (conv_in): Conv2d(4, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (time_proj): Timesteps()\n",
       "  (time_embedding): TimestepEmbedding(\n",
       "    (linear_1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "    (act): SiLU()\n",
       "    (linear_2): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "  )\n",
       "  (down_blocks): ModuleList(\n",
       "    (0): CrossAttnDownBlock2D(\n",
       "      (attentions): ModuleList(\n",
       "        (0-1): 2 x Transformer2DModel(\n",
       "          (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "          (proj_in): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn1): Attention(\n",
       "                (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn2): Attention(\n",
       "                (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_k): Linear(in_features=1024, out_features=320, bias=False)\n",
       "                (to_v): Linear(in_features=1024, out_features=320, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (ff): FeedForward(\n",
       "                (net): ModuleList(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Linear(in_features=320, out_features=320, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (resnets): ModuleList(\n",
       "        (0-1): 2 x ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (norm2): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "        )\n",
       "      )\n",
       "      (downsamplers): ModuleList(\n",
       "        (0): Downsample2D(\n",
       "          (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): CrossAttnDownBlock2D(\n",
       "      (attentions): ModuleList(\n",
       "        (0-1): 2 x Transformer2DModel(\n",
       "          (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "          (proj_in): Linear(in_features=640, out_features=640, bias=True)\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn1): Attention(\n",
       "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn2): Attention(\n",
       "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): Linear(in_features=1024, out_features=640, bias=False)\n",
       "                (to_v): Linear(in_features=1024, out_features=640, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (ff): FeedForward(\n",
       "                (net): ModuleList(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Linear(in_features=640, out_features=640, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (resnets): ModuleList(\n",
       "        (0): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(320, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=1280, out_features=640, bias=True)\n",
       "          (norm2): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): Conv2d(320, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=1280, out_features=640, bias=True)\n",
       "          (norm2): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "        )\n",
       "      )\n",
       "      (downsamplers): ModuleList(\n",
       "        (0): Downsample2D(\n",
       "          (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): CrossAttnDownBlock2D(\n",
       "      (attentions): ModuleList(\n",
       "        (0-1): 2 x Transformer2DModel(\n",
       "          (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "          (proj_in): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn1): Attention(\n",
       "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn2): Attention(\n",
       "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): Linear(in_features=1024, out_features=1280, bias=False)\n",
       "                (to_v): Linear(in_features=1024, out_features=1280, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (ff): FeedForward(\n",
       "                (net): ModuleList(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (resnets): ModuleList(\n",
       "        (0): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(640, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): Conv2d(640, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "        )\n",
       "      )\n",
       "      (downsamplers): ModuleList(\n",
       "        (0): Downsample2D(\n",
       "          (conv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): DownBlock2D(\n",
       "      (resnets): ModuleList(\n",
       "        (0-1): 2 x ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up_blocks): ModuleList(\n",
       "    (0): UpBlock2D(\n",
       "      (resnets): ModuleList(\n",
       "        (0-2): 3 x ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 2560, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (upsamplers): ModuleList(\n",
       "        (0): Upsample2D(\n",
       "          (conv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): CrossAttnUpBlock2D(\n",
       "      (attentions): ModuleList(\n",
       "        (0-2): 3 x Transformer2DModel(\n",
       "          (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "          (proj_in): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn1): Attention(\n",
       "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn2): Attention(\n",
       "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): Linear(in_features=1024, out_features=1280, bias=False)\n",
       "                (to_v): Linear(in_features=1024, out_features=1280, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (ff): FeedForward(\n",
       "                (net): ModuleList(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (resnets): ModuleList(\n",
       "        (0-1): 2 x ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 2560, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 1920, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(1920, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): Conv2d(1920, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (upsamplers): ModuleList(\n",
       "        (0): Upsample2D(\n",
       "          (conv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): CrossAttnUpBlock2D(\n",
       "      (attentions): ModuleList(\n",
       "        (0-2): 3 x Transformer2DModel(\n",
       "          (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "          (proj_in): Linear(in_features=640, out_features=640, bias=True)\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn1): Attention(\n",
       "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn2): Attention(\n",
       "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): Linear(in_features=1024, out_features=640, bias=False)\n",
       "                (to_v): Linear(in_features=1024, out_features=640, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (ff): FeedForward(\n",
       "                (net): ModuleList(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Linear(in_features=640, out_features=640, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (resnets): ModuleList(\n",
       "        (0): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 1920, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(1920, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=1280, out_features=640, bias=True)\n",
       "          (norm2): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): Conv2d(1920, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(1280, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=1280, out_features=640, bias=True)\n",
       "          (norm2): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 960, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(960, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=1280, out_features=640, bias=True)\n",
       "          (norm2): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): Conv2d(960, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (upsamplers): ModuleList(\n",
       "        (0): Upsample2D(\n",
       "          (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): CrossAttnUpBlock2D(\n",
       "      (attentions): ModuleList(\n",
       "        (0-2): 3 x Transformer2DModel(\n",
       "          (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "          (proj_in): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn1): Attention(\n",
       "                (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn2): Attention(\n",
       "                (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_k): Linear(in_features=1024, out_features=320, bias=False)\n",
       "                (to_v): Linear(in_features=1024, out_features=320, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (ff): FeedForward(\n",
       "                (net): ModuleList(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Linear(in_features=320, out_features=320, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (resnets): ModuleList(\n",
       "        (0): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 960, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(960, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (norm2): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1-2): 2 x ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(640, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (norm2): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (mid_block): UNetMidBlock2DCrossAttn(\n",
       "    (attentions): ModuleList(\n",
       "      (0): Transformer2DModel(\n",
       "        (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "        (proj_in): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (transformer_blocks): ModuleList(\n",
       "          (0): BasicTransformerBlock(\n",
       "            (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn1): Attention(\n",
       "              (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_out): ModuleList(\n",
       "                (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn2): Attention(\n",
       "              (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_k): Linear(in_features=1024, out_features=1280, bias=False)\n",
       "              (to_v): Linear(in_features=1024, out_features=1280, bias=False)\n",
       "              (to_out): ModuleList(\n",
       "                (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (ff): FeedForward(\n",
       "              (net): ModuleList(\n",
       "                (0): GEGLU(\n",
       "                  (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (proj_out): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (resnets): ModuleList(\n",
       "      (0-1): 2 x ResnetBlock2D(\n",
       "        (norm1): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "        (conv1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (time_emb_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (conv2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (nonlinearity): SiLU()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (conv_norm_out): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
       "  (conv_act): SiLU()\n",
       "  (conv_out): Conv2d(320, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       ")\n",
       "\u001b[0;31mFile:\u001b[0m           ~/miniconda3/envs/dl-env/lib/python3.8/site-packages/diffusers/models/unet_2d_condition.py\n",
       "\u001b[0;31mSource:\u001b[0m        \n",
       "\u001b[0;32mclass\u001b[0m \u001b[0mUNet2DConditionModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModelMixin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConfigMixin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUNet2DConditionLoadersMixin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34mr\"\"\"\u001b[0m\n",
       "\u001b[0;34m    A conditional 2D UNet model that takes a noisy sample, conditional state, and a timestep and returns a sample\u001b[0m\n",
       "\u001b[0;34m    shaped output.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    This model inherits from [`ModelMixin`]. Check the superclass documentation for it's generic methods implemented\u001b[0m\n",
       "\u001b[0;34m    for all models (such as downloading or saving).\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Parameters:\u001b[0m\n",
       "\u001b[0;34m        sample_size (`int` or `Tuple[int, int]`, *optional*, defaults to `None`):\u001b[0m\n",
       "\u001b[0;34m            Height and width of input/output sample.\u001b[0m\n",
       "\u001b[0;34m        in_channels (`int`, *optional*, defaults to 4): Number of channels in the input sample.\u001b[0m\n",
       "\u001b[0;34m        out_channels (`int`, *optional*, defaults to 4): Number of channels in the output.\u001b[0m\n",
       "\u001b[0;34m        center_input_sample (`bool`, *optional*, defaults to `False`): Whether to center the input sample.\u001b[0m\n",
       "\u001b[0;34m        flip_sin_to_cos (`bool`, *optional*, defaults to `False`):\u001b[0m\n",
       "\u001b[0;34m            Whether to flip the sin to cos in the time embedding.\u001b[0m\n",
       "\u001b[0;34m        freq_shift (`int`, *optional*, defaults to 0): The frequency shift to apply to the time embedding.\u001b[0m\n",
       "\u001b[0;34m        down_block_types (`Tuple[str]`, *optional*, defaults to `(\"CrossAttnDownBlock2D\", \"CrossAttnDownBlock2D\", \"CrossAttnDownBlock2D\", \"DownBlock2D\")`):\u001b[0m\n",
       "\u001b[0;34m            The tuple of downsample blocks to use.\u001b[0m\n",
       "\u001b[0;34m        mid_block_type (`str`, *optional*, defaults to `\"UNetMidBlock2DCrossAttn\"`):\u001b[0m\n",
       "\u001b[0;34m            Block type for middle of UNet, it can be either `UNetMidBlock2DCrossAttn` or\u001b[0m\n",
       "\u001b[0;34m            `UNetMidBlock2DSimpleCrossAttn`. If `None`, the mid block layer is skipped.\u001b[0m\n",
       "\u001b[0;34m        up_block_types (`Tuple[str]`, *optional*, defaults to `(\"UpBlock2D\", \"CrossAttnUpBlock2D\", \"CrossAttnUpBlock2D\", \"CrossAttnUpBlock2D\")`):\u001b[0m\n",
       "\u001b[0;34m            The tuple of upsample blocks to use.\u001b[0m\n",
       "\u001b[0;34m        only_cross_attention(`bool` or `Tuple[bool]`, *optional*, default to `False`):\u001b[0m\n",
       "\u001b[0;34m            Whether to include self-attention in the basic transformer blocks, see\u001b[0m\n",
       "\u001b[0;34m            [`~models.attention.BasicTransformerBlock`].\u001b[0m\n",
       "\u001b[0;34m        block_out_channels (`Tuple[int]`, *optional*, defaults to `(320, 640, 1280, 1280)`):\u001b[0m\n",
       "\u001b[0;34m            The tuple of output channels for each block.\u001b[0m\n",
       "\u001b[0;34m        layers_per_block (`int`, *optional*, defaults to 2): The number of layers per block.\u001b[0m\n",
       "\u001b[0;34m        downsample_padding (`int`, *optional*, defaults to 1): The padding to use for the downsampling convolution.\u001b[0m\n",
       "\u001b[0;34m        mid_block_scale_factor (`float`, *optional*, defaults to 1.0): The scale factor to use for the mid block.\u001b[0m\n",
       "\u001b[0;34m        act_fn (`str`, *optional*, defaults to `\"silu\"`): The activation function to use.\u001b[0m\n",
       "\u001b[0;34m        norm_num_groups (`int`, *optional*, defaults to 32): The number of groups to use for the normalization.\u001b[0m\n",
       "\u001b[0;34m            If `None`, normalization and activation layers is skipped in post-processing.\u001b[0m\n",
       "\u001b[0;34m        norm_eps (`float`, *optional*, defaults to 1e-5): The epsilon to use for the normalization.\u001b[0m\n",
       "\u001b[0;34m        cross_attention_dim (`int` or `Tuple[int]`, *optional*, defaults to 1280):\u001b[0m\n",
       "\u001b[0;34m            The dimension of the cross attention features.\u001b[0m\n",
       "\u001b[0;34m        transformer_layers_per_block (`int` or `Tuple[int]`, *optional*, defaults to 1):\u001b[0m\n",
       "\u001b[0;34m            The number of transformer blocks of type [`~models.attention.BasicTransformerBlock`]. Only relevant for\u001b[0m\n",
       "\u001b[0;34m            [`~models.unet_2d_blocks.CrossAttnDownBlock2D`], [`~models.unet_2d_blocks.CrossAttnUpBlock2D`],\u001b[0m\n",
       "\u001b[0;34m            [`~models.unet_2d_blocks.UNetMidBlock2DCrossAttn`].\u001b[0m\n",
       "\u001b[0;34m        encoder_hid_dim (`int`, *optional*, defaults to None):\u001b[0m\n",
       "\u001b[0;34m            If `encoder_hid_dim_type` is defined, `encoder_hidden_states` will be projected from `encoder_hid_dim`\u001b[0m\n",
       "\u001b[0;34m            dimension to `cross_attention_dim`.\u001b[0m\n",
       "\u001b[0;34m        encoder_hid_dim_type (`str`, *optional*, defaults to `None`):\u001b[0m\n",
       "\u001b[0;34m            If given, the `encoder_hidden_states` and potentially other embeddings are down-projected to text\u001b[0m\n",
       "\u001b[0;34m            embeddings of dimension `cross_attention` according to `encoder_hid_dim_type`.\u001b[0m\n",
       "\u001b[0;34m        attention_head_dim (`int`, *optional*, defaults to 8): The dimension of the attention heads.\u001b[0m\n",
       "\u001b[0;34m        num_attention_heads (`int`, *optional*):\u001b[0m\n",
       "\u001b[0;34m            The number of attention heads. If not defined, defaults to `attention_head_dim`\u001b[0m\n",
       "\u001b[0;34m        resnet_time_scale_shift (`str`, *optional*, defaults to `\"default\"`): Time scale shift config\u001b[0m\n",
       "\u001b[0;34m            for ResNet blocks (see [`~models.resnet.ResnetBlock2D`]). Choose from `default` or `scale_shift`.\u001b[0m\n",
       "\u001b[0;34m        class_embed_type (`str`, *optional*, defaults to `None`):\u001b[0m\n",
       "\u001b[0;34m            The type of class embedding to use which is ultimately summed with the time embeddings. Choose from `None`,\u001b[0m\n",
       "\u001b[0;34m            `\"timestep\"`, `\"identity\"`, `\"projection\"`, or `\"simple_projection\"`.\u001b[0m\n",
       "\u001b[0;34m        addition_embed_type (`str`, *optional*, defaults to `None`):\u001b[0m\n",
       "\u001b[0;34m            Configures an optional embedding which will be summed with the time embeddings. Choose from `None` or\u001b[0m\n",
       "\u001b[0;34m            \"text\". \"text\" will use the `TextTimeEmbedding` layer.\u001b[0m\n",
       "\u001b[0;34m        addition_time_embed_dim: (`int`, *optional*, defaults to `None`):\u001b[0m\n",
       "\u001b[0;34m            Dimension for the timestep embeddings.\u001b[0m\n",
       "\u001b[0;34m        num_class_embeds (`int`, *optional*, defaults to `None`):\u001b[0m\n",
       "\u001b[0;34m            Input dimension of the learnable embedding matrix to be projected to `time_embed_dim`, when performing\u001b[0m\n",
       "\u001b[0;34m            class conditioning with `class_embed_type` equal to `None`.\u001b[0m\n",
       "\u001b[0;34m        time_embedding_type (`str`, *optional*, defaults to `positional`):\u001b[0m\n",
       "\u001b[0;34m            The type of position embedding to use for timesteps. Choose from `positional` or `fourier`.\u001b[0m\n",
       "\u001b[0;34m        time_embedding_dim (`int`, *optional*, defaults to `None`):\u001b[0m\n",
       "\u001b[0;34m            An optional override for the dimension of the projected time embedding.\u001b[0m\n",
       "\u001b[0;34m        time_embedding_act_fn (`str`, *optional*, defaults to `None`):\u001b[0m\n",
       "\u001b[0;34m            Optional activation function to use only once on the time embeddings before they are passed to the rest of\u001b[0m\n",
       "\u001b[0;34m            the UNet. Choose from `silu`, `mish`, `gelu`, and `swish`.\u001b[0m\n",
       "\u001b[0;34m        timestep_post_act (`str`, *optional*, defaults to `None`):\u001b[0m\n",
       "\u001b[0;34m            The second activation function to use in timestep embedding. Choose from `silu`, `mish` and `gelu`.\u001b[0m\n",
       "\u001b[0;34m        time_cond_proj_dim (`int`, *optional*, defaults to `None`):\u001b[0m\n",
       "\u001b[0;34m            The dimension of `cond_proj` layer in the timestep embedding.\u001b[0m\n",
       "\u001b[0;34m        conv_in_kernel (`int`, *optional*, default to `3`): The kernel size of `conv_in` layer.\u001b[0m\n",
       "\u001b[0;34m        conv_out_kernel (`int`, *optional*, default to `3`): The kernel size of `conv_out` layer.\u001b[0m\n",
       "\u001b[0;34m        projection_class_embeddings_input_dim (`int`, *optional*): The dimension of the `class_labels` input when\u001b[0m\n",
       "\u001b[0;34m            `class_embed_type=\"projection\"`. Required when `class_embed_type=\"projection\"`.\u001b[0m\n",
       "\u001b[0;34m        class_embeddings_concat (`bool`, *optional*, defaults to `False`): Whether to concatenate the time\u001b[0m\n",
       "\u001b[0;34m            embeddings with the class embeddings.\u001b[0m\n",
       "\u001b[0;34m        mid_block_only_cross_attention (`bool`, *optional*, defaults to `None`):\u001b[0m\n",
       "\u001b[0;34m            Whether to use cross attention with the mid block when using the `UNetMidBlock2DSimpleCrossAttn`. If\u001b[0m\n",
       "\u001b[0;34m            `only_cross_attention` is given as a single boolean and `mid_block_only_cross_attention` is `None`, the\u001b[0m\n",
       "\u001b[0;34m            `only_cross_attention` value is used as the value for `mid_block_only_cross_attention`. Default to `False`\u001b[0m\n",
       "\u001b[0;34m            otherwise.\u001b[0m\n",
       "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0m_supports_gradient_checkpointing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m@\u001b[0m\u001b[0mregister_to_config\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0msample_size\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0min_channels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mout_channels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mcenter_input_sample\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mflip_sin_to_cos\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mfreq_shift\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mdown_block_types\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m\"CrossAttnDownBlock2D\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m\"CrossAttnDownBlock2D\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m\"CrossAttnDownBlock2D\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m\"DownBlock2D\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mmid_block_type\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"UNetMidBlock2DCrossAttn\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mup_block_types\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"UpBlock2D\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"CrossAttnUpBlock2D\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"CrossAttnUpBlock2D\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"CrossAttnUpBlock2D\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0monly_cross_attention\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mblock_out_channels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m320\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m640\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1280\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1280\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mlayers_per_block\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mdownsample_padding\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mmid_block_scale_factor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mact_fn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"silu\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mnorm_num_groups\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mnorm_eps\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mcross_attention_dim\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1280\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mtransformer_layers_per_block\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mencoder_hid_dim\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mencoder_hid_dim_type\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mattention_head_dim\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mnum_attention_heads\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mdual_cross_attention\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0muse_linear_projection\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mclass_embed_type\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0maddition_embed_type\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0maddition_time_embed_dim\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mnum_class_embeds\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mupcast_attention\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mresnet_time_scale_shift\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"default\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mresnet_skip_time_act\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mresnet_out_scale_factor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mtime_embedding_type\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"positional\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mtime_embedding_dim\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mtime_embedding_act_fn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mtimestep_post_act\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mtime_cond_proj_dim\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mconv_in_kernel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mconv_out_kernel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mprojection_class_embeddings_input_dim\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mclass_embeddings_concat\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mmid_block_only_cross_attention\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mcross_attention_norm\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0maddition_embed_type_num_heads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_size\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mnum_attention_heads\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;34m\"At the moment it is not possible to define the number of attention heads via `num_attention_heads` because of a naming issue as described in https://github.com/huggingface/diffusers/issues/2011#issuecomment-1547958131. Passing `num_attention_heads` will only be supported in diffusers v0.19.\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# If `num_attention_heads` is not defined (which is the case for most models)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# it will default to `attention_head_dim`. This looks weird upon first reading it and it is.\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# The reason for this behavior is to correct for incorrectly named variables that were introduced\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# when this library was created. The incorrect naming was only discovered much later in https://github.com/huggingface/diffusers/issues/2011#issuecomment-1547958131\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# Changing `attention_head_dim` to `num_attention_heads` for 40,000+ configurations is too backwards breaking\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# which is why we correct for the naming here.\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mnum_attention_heads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_attention_heads\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mattention_head_dim\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# Check inputs\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdown_block_types\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mup_block_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;34mf\"Must provide the same number of `down_block_types` as `up_block_types`. `down_block_types`: {down_block_types}. `up_block_types`: {up_block_types}.\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock_out_channels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdown_block_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;34mf\"Must provide the same number of `block_out_channels` as `down_block_types`. `block_out_channels`: {block_out_channels}. `down_block_types`: {down_block_types}.\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0monly_cross_attention\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0monly_cross_attention\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdown_block_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;34mf\"Must provide the same number of `only_cross_attention` as `down_block_types`. `only_cross_attention`: {only_cross_attention}. `down_block_types`: {down_block_types}.\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_attention_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_attention_heads\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdown_block_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;34mf\"Must provide the same number of `num_attention_heads` as `down_block_types`. `num_attention_heads`: {num_attention_heads}. `down_block_types`: {down_block_types}.\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_head_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_head_dim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdown_block_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;34mf\"Must provide the same number of `attention_head_dim` as `down_block_types`. `attention_head_dim`: {attention_head_dim}. `down_block_types`: {down_block_types}.\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcross_attention_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcross_attention_dim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdown_block_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;34mf\"Must provide the same number of `cross_attention_dim` as `down_block_types`. `cross_attention_dim`: {cross_attention_dim}. `down_block_types`: {down_block_types}.\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers_per_block\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers_per_block\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdown_block_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;34mf\"Must provide the same number of `layers_per_block` as `down_block_types`. `layers_per_block`: {layers_per_block}. `down_block_types`: {down_block_types}.\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# input\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mconv_in_padding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mconv_in_kernel\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0min_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_out_channels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconv_in_kernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconv_in_padding\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# time\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mtime_embedding_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"fourier\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mtime_embed_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime_embedding_dim\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mblock_out_channels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mtime_embed_dim\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"`time_embed_dim` should be divisible by 2, but is {time_embed_dim}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime_proj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGaussianFourierProjection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mtime_embed_dim\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_W_to_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflip_sin_to_cos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflip_sin_to_cos\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mtimestep_input_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime_embed_dim\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32melif\u001b[0m \u001b[0mtime_embedding_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"positional\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mtime_embed_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime_embedding_dim\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mblock_out_channels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime_proj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTimesteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock_out_channels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflip_sin_to_cos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfreq_shift\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mtimestep_input_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock_out_channels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;34mf\"{time_embedding_type} does not exist. Please make sure to use one of `fourier` or `positional`.\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTimestepEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mtimestep_input_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mtime_embed_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mact_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mact_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mpost_act_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimestep_post_act\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mcond_proj_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime_cond_proj_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mencoder_hid_dim_type\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mencoder_hid_dim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mencoder_hid_dim_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"text_proj\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_to_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_hid_dim_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_hid_dim_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoder_hid_dim_type defaults to 'text_proj' as `encoder_hid_dim` is defined.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mencoder_hid_dim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mencoder_hid_dim_type\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;34mf\"`encoder_hid_dim` has to be defined when `encoder_hid_dim_type` is set to {encoder_hid_dim_type}.\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mencoder_hid_dim_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"text_proj\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder_hid_proj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_hid_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcross_attention_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32melif\u001b[0m \u001b[0mencoder_hid_dim_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"text_image_proj\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;31m# image_embed_dim DOESN'T have to be `cross_attention_dim`. To not clutter the __init__ too much\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;31m# they are set to `cross_attention_dim` here as this is exactly the required dimension for the currently only use\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;31m# case when `addition_embed_type == \"text_image_proj\"` (Kadinsky 2.1)`\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder_hid_proj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextImageProjection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mtext_embed_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_hid_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mimage_embed_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcross_attention_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mcross_attention_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcross_attention_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32melif\u001b[0m \u001b[0mencoder_hid_dim_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"image_proj\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;31m# Kandinsky 2.2\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder_hid_proj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageProjection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mimage_embed_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_hid_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mcross_attention_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcross_attention_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32melif\u001b[0m \u001b[0mencoder_hid_dim_type\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;34mf\"encoder_hid_dim_type: {encoder_hid_dim_type} must be None, 'text_proj' or 'text_image_proj'.\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder_hid_proj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# class embedding\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mclass_embed_type\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnum_class_embeds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_class_embeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_embed_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32melif\u001b[0m \u001b[0mclass_embed_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"timestep\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTimestepEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimestep_input_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_embed_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mact_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mact_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32melif\u001b[0m \u001b[0mclass_embed_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"identity\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIdentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime_embed_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_embed_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32melif\u001b[0m \u001b[0mclass_embed_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"projection\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mprojection_class_embeddings_input_dim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0;34m\"`class_embed_type`: 'projection' requires `projection_class_embeddings_input_dim` be set\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;31m# The projection `class_embed_type` is the same as the timestep `class_embed_type` except\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;31m# 1. the `class_labels` inputs are not first converted to sinusoidal embeddings\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;31m# 2. it projects from an arbitrary input dimension.\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;31m# Note that `TimestepEmbedding` is quite general, being mainly linear layers and activations.\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;31m# When used for embedding actual timesteps, the timesteps are first converted to sinusoidal embeddings.\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;31m# As a result, `TimestepEmbedding` can be passed arbitrary vectors.\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTimestepEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprojection_class_embeddings_input_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_embed_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32melif\u001b[0m \u001b[0mclass_embed_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"simple_projection\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mprojection_class_embeddings_input_dim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0;34m\"`class_embed_type`: 'simple_projection' requires `projection_class_embeddings_input_dim` be set\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprojection_class_embeddings_input_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_embed_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0maddition_embed_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"text\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mencoder_hid_dim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mtext_time_embedding_from_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_hid_dim\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mtext_time_embedding_from_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_attention_dim\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextTimeEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mtext_time_embedding_from_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_embed_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_heads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maddition_embed_type_num_heads\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32melif\u001b[0m \u001b[0maddition_embed_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"text_image\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;31m# text_embed_dim and image_embed_dim DON'T have to be `cross_attention_dim`. To not clutter the __init__ too much\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;31m# they are set to `cross_attention_dim` here as this is exactly the required dimension for the currently only use\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;31m# case when `addition_embed_type == \"text_image\"` (Kadinsky 2.1)`\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextImageTimeEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mtext_embed_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcross_attention_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_embed_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcross_attention_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_embed_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime_embed_dim\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32melif\u001b[0m \u001b[0maddition_embed_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"text_time\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_time_proj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTimesteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maddition_time_embed_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflip_sin_to_cos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfreq_shift\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTimestepEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprojection_class_embeddings_input_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_embed_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32melif\u001b[0m \u001b[0maddition_embed_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"image\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;31m# Kandinsky 2.2\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageTimeEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_embed_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_hid_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_embed_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime_embed_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32melif\u001b[0m \u001b[0maddition_embed_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"image_hint\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;31m# Kandinsky 2.2 ControlNet\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageHintTimeEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_embed_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_hid_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_embed_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime_embed_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32melif\u001b[0m \u001b[0maddition_embed_type\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"addition_embed_type: {addition_embed_type} must be None, 'text' or 'text_image'.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mtime_embedding_act_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime_embed_act\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime_embed_act\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_activation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime_embedding_act_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdown_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModuleList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mup_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModuleList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0monly_cross_attention\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mmid_block_only_cross_attention\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mmid_block_only_cross_attention\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0monly_cross_attention\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0monly_cross_attention\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0monly_cross_attention\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdown_block_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mmid_block_only_cross_attention\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mmid_block_only_cross_attention\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_attention_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mnum_attention_heads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnum_attention_heads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdown_block_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_head_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mattention_head_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mattention_head_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdown_block_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcross_attention_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mcross_attention_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcross_attention_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdown_block_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers_per_block\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mlayers_per_block\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlayers_per_block\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdown_block_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer_layers_per_block\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mtransformer_layers_per_block\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtransformer_layers_per_block\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdown_block_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mclass_embeddings_concat\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;31m# The time embeddings are concatenated with the class embeddings. The dimension of the\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;31m# time embeddings passed to the down, middle, and up blocks is twice the dimension of the\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;31m# regular time embeddings\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mblocks_time_embed_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime_embed_dim\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mblocks_time_embed_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime_embed_dim\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# down\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0moutput_channel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock_out_channels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdown_block_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdown_block_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0minput_channel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_channel\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0moutput_channel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock_out_channels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mis_final_block\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock_out_channels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mdown_block\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_down_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mdown_block_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mnum_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayers_per_block\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mtransformer_layers_per_block\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransformer_layers_per_block\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0min_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_channel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mout_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_channel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mtemb_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mblocks_time_embed_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0madd_downsample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mis_final_block\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mresnet_eps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnorm_eps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mresnet_act_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mact_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mresnet_groups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnorm_num_groups\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mcross_attention_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcross_attention_dim\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mnum_attention_heads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_attention_heads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mdownsample_padding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownsample_padding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mdual_cross_attention\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdual_cross_attention\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0muse_linear_projection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_linear_projection\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0monly_cross_attention\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0monly_cross_attention\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mupcast_attention\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupcast_attention\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mresnet_time_scale_shift\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresnet_time_scale_shift\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mresnet_skip_time_act\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresnet_skip_time_act\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mresnet_out_scale_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresnet_out_scale_factor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mcross_attention_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcross_attention_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mattention_head_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_head_dim\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mattention_head_dim\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0moutput_channel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdown_blocks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdown_block\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# mid\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mmid_block_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"UNetMidBlock2DCrossAttn\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmid_block\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUNetMidBlock2DCrossAttn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mtransformer_layers_per_block\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransformer_layers_per_block\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0min_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mblock_out_channels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mtemb_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mblocks_time_embed_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mresnet_eps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnorm_eps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mresnet_act_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mact_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0moutput_scale_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmid_block_scale_factor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mresnet_time_scale_shift\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresnet_time_scale_shift\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mcross_attention_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcross_attention_dim\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mnum_attention_heads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_attention_heads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mresnet_groups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnorm_num_groups\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mdual_cross_attention\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdual_cross_attention\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0muse_linear_projection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_linear_projection\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mupcast_attention\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupcast_attention\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32melif\u001b[0m \u001b[0mmid_block_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"UNetMidBlock2DSimpleCrossAttn\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmid_block\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUNetMidBlock2DSimpleCrossAttn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0min_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mblock_out_channels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mtemb_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mblocks_time_embed_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mresnet_eps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnorm_eps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mresnet_act_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mact_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0moutput_scale_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmid_block_scale_factor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mcross_attention_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcross_attention_dim\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mattention_head_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_head_dim\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mresnet_groups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnorm_num_groups\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mresnet_time_scale_shift\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresnet_time_scale_shift\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mskip_time_act\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresnet_skip_time_act\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0monly_cross_attention\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmid_block_only_cross_attention\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mcross_attention_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcross_attention_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32melif\u001b[0m \u001b[0mmid_block_type\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmid_block\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"unknown mid_block_type : {mid_block_type}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# count how many layers upsample the images\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_upsamplers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# up\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mreversed_block_out_channels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock_out_channels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mreversed_num_attention_heads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_attention_heads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mreversed_layers_per_block\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers_per_block\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mreversed_cross_attention_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcross_attention_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mreversed_transformer_layers_per_block\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer_layers_per_block\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0monly_cross_attention\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0monly_cross_attention\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0moutput_channel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreversed_block_out_channels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mup_block_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mup_block_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mis_final_block\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock_out_channels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mprev_output_channel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_channel\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0moutput_channel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreversed_block_out_channels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0minput_channel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreversed_block_out_channels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock_out_channels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;31m# add upsample block for all BUT final layer\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_final_block\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0madd_upsample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_upsamplers\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0madd_upsample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mup_block\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_up_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mup_block_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mnum_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreversed_layers_per_block\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mtransformer_layers_per_block\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreversed_transformer_layers_per_block\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0min_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_channel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mout_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_channel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mprev_output_channel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprev_output_channel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mtemb_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mblocks_time_embed_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0madd_upsample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0madd_upsample\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mresnet_eps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnorm_eps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mresnet_act_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mact_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mresnet_groups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnorm_num_groups\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mcross_attention_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreversed_cross_attention_dim\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mnum_attention_heads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreversed_num_attention_heads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mdual_cross_attention\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdual_cross_attention\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0muse_linear_projection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_linear_projection\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0monly_cross_attention\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0monly_cross_attention\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mupcast_attention\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupcast_attention\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mresnet_time_scale_shift\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresnet_time_scale_shift\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mresnet_skip_time_act\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresnet_skip_time_act\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mresnet_out_scale_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresnet_out_scale_factor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mcross_attention_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcross_attention_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mattention_head_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_head_dim\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mattention_head_dim\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0moutput_channel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mup_blocks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mup_block\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mprev_output_channel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_channel\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# out\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mnorm_num_groups\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_norm_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGroupNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mnum_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mblock_out_channels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_groups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnorm_num_groups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnorm_eps\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_act\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_activation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mact_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_norm_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_act\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mconv_out_padding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mconv_out_kernel\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mblock_out_channels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconv_out_kernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconv_out_padding\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mattn_processors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAttentionProcessor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34mr\"\"\"\u001b[0m\n",
       "\u001b[0;34m        Returns:\u001b[0m\n",
       "\u001b[0;34m            `dict` of attention processors: A dictionary containing all attention processors used in the model with\u001b[0m\n",
       "\u001b[0;34m            indexed by its weight name.\u001b[0m\n",
       "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# set recursively\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mprocessors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mdef\u001b[0m \u001b[0mfn_recursive_add_processors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocessors\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAttentionProcessor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"set_processor\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mprocessors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf\"{name}.processor\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mfor\u001b[0m \u001b[0msub_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchild\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_children\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mfn_recursive_add_processors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{name}.{sub_name}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchild\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocessors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mreturn\u001b[0m \u001b[0mprocessors\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_children\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mfn_recursive_add_processors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocessors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mprocessors\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mset_attn_processor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocessor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAttentionProcessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAttentionProcessor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34mr\"\"\"\u001b[0m\n",
       "\u001b[0;34m        Sets the attention processor to use to compute attention.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Parameters:\u001b[0m\n",
       "\u001b[0;34m            processor (`dict` of `AttentionProcessor` or only `AttentionProcessor`):\u001b[0m\n",
       "\u001b[0;34m                The instantiated processor class or a dictionary of processor classes that will be set as the processor\u001b[0m\n",
       "\u001b[0;34m                for **all** `Attention` layers.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m                If `processor` is a dict, the key needs to define the path to the corresponding cross attention\u001b[0m\n",
       "\u001b[0;34m                processor. This is strongly recommended when setting trainable attention processors.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattn_processors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;34mf\"A dict of processors was passed, but the number of processors {len(processor)} does not match the\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;34mf\" number of attention layers: {count}. Please make sure to pass {count} processor classes.\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mdef\u001b[0m \u001b[0mfn_recursive_attn_processor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocessor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"set_processor\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_processor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_processor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{name}.processor\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mfor\u001b[0m \u001b[0msub_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchild\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_children\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mfn_recursive_attn_processor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{name}.{sub_name}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchild\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocessor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_children\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mfn_recursive_attn_processor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocessor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mset_default_attn_processor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"\u001b[0m\n",
       "\u001b[0;34m        Disables custom attention processors and sets the default attention implementation.\u001b[0m\n",
       "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_attn_processor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAttnProcessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mset_attention_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34mr\"\"\"\u001b[0m\n",
       "\u001b[0;34m        Enable sliced attention computation.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        When this option is enabled, the attention module splits the input tensor in slices to compute attention in\u001b[0m\n",
       "\u001b[0;34m        several steps. This is useful for saving some memory in exchange for a small decrease in speed.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Args:\u001b[0m\n",
       "\u001b[0;34m            slice_size (`str` or `int` or `list(int)`, *optional*, defaults to `\"auto\"`):\u001b[0m\n",
       "\u001b[0;34m                When `\"auto\"`, input to the attention heads is halved, so attention is computed in two steps. If\u001b[0m\n",
       "\u001b[0;34m                `\"max\"`, maximum amount of memory is saved by running only one slice at a time. If a number is\u001b[0m\n",
       "\u001b[0;34m                provided, uses as many slices as `attention_head_dim // slice_size`. In this case, `attention_head_dim`\u001b[0m\n",
       "\u001b[0;34m                must be a multiple of `slice_size`.\u001b[0m\n",
       "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0msliceable_head_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mdef\u001b[0m \u001b[0mfn_recursive_retrieve_sliceable_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"set_attention_slice\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0msliceable_head_dims\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msliceable_head_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mfor\u001b[0m \u001b[0mchild\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mfn_recursive_retrieve_sliceable_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# retrieve number of attention layers\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mfn_recursive_retrieve_sliceable_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mnum_sliceable_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msliceable_head_dims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mslice_size\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"auto\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;31m# half the attention head size is usually a good trade-off between\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;31m# speed and memory\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mslice_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdim\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msliceable_head_dims\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32melif\u001b[0m \u001b[0mslice_size\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"max\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;31m# make smallest slice possible\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mslice_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_sliceable_layers\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mslice_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_sliceable_layers\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mslice_size\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslice_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mslice_size\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslice_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msliceable_head_dims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;34mf\"You have provided {len(slice_size)}, but {self.config} has {len(sliceable_head_dims)} different\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;34mf\" attention layers. Make sure to match `len(slice_size)` to be {len(sliceable_head_dims)}.\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslice_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice_size\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msliceable_head_dims\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0msize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"size {size} has to be smaller or equal to {dim}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# Recursively walk through all the children.\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# Any children which exposes the set_attention_slice method\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# gets the message\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mdef\u001b[0m \u001b[0mfn_recursive_set_attention_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice_size\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"set_attention_slice\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_attention_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslice_size\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mfor\u001b[0m \u001b[0mchild\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mfn_recursive_set_attention_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mreversed_slice_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslice_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mfn_recursive_set_attention_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreversed_slice_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m_set_gradient_checkpointing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mCrossAttnDownBlock2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDownBlock2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCrossAttnUpBlock2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUpBlock2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient_checkpointing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0msample\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mtimestep\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mclass_labels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mtimestep_cond\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mattention_mask\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mcross_attention_kwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0madded_cond_kwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mdown_block_additional_residuals\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mmid_block_additional_residual\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mreturn_dict\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUNet2DConditionOutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34mr\"\"\"\u001b[0m\n",
       "\u001b[0;34m        The [`UNet2DConditionModel`] forward method.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Args:\u001b[0m\n",
       "\u001b[0;34m            sample (`torch.FloatTensor`):\u001b[0m\n",
       "\u001b[0;34m                The noisy input tensor with the following shape `(batch, channel, height, width)`.\u001b[0m\n",
       "\u001b[0;34m            timestep (`torch.FloatTensor` or `float` or `int`): The number of timesteps to denoise an input.\u001b[0m\n",
       "\u001b[0;34m            encoder_hidden_states (`torch.FloatTensor`):\u001b[0m\n",
       "\u001b[0;34m                The encoder hidden states with shape `(batch, sequence_length, feature_dim)`.\u001b[0m\n",
       "\u001b[0;34m            encoder_attention_mask (`torch.Tensor`):\u001b[0m\n",
       "\u001b[0;34m                A cross-attention mask of shape `(batch, sequence_length)` is applied to `encoder_hidden_states`. If\u001b[0m\n",
       "\u001b[0;34m                `True` the mask is kept, otherwise if `False` it is discarded. Mask will be converted into a bias,\u001b[0m\n",
       "\u001b[0;34m                which adds large negative values to the attention scores corresponding to \"discard\" tokens.\u001b[0m\n",
       "\u001b[0;34m            return_dict (`bool`, *optional*, defaults to `True`):\u001b[0m\n",
       "\u001b[0;34m                Whether or not to return a [`~models.unet_2d_condition.UNet2DConditionOutput`] instead of a plain\u001b[0m\n",
       "\u001b[0;34m                tuple.\u001b[0m\n",
       "\u001b[0;34m            cross_attention_kwargs (`dict`, *optional*):\u001b[0m\n",
       "\u001b[0;34m                A kwargs dictionary that if specified is passed along to the [`AttnProcessor`].\u001b[0m\n",
       "\u001b[0;34m            added_cond_kwargs: (`dict`, *optional*):\u001b[0m\n",
       "\u001b[0;34m                A kwargs dictionary containin additional embeddings that if specified are added to the embeddings that\u001b[0m\n",
       "\u001b[0;34m                are passed along to the UNet blocks.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Returns:\u001b[0m\n",
       "\u001b[0;34m            [`~models.unet_2d_condition.UNet2DConditionOutput`] or `tuple`:\u001b[0m\n",
       "\u001b[0;34m                If `return_dict` is True, an [`~models.unet_2d_condition.UNet2DConditionOutput`] is returned, otherwise\u001b[0m\n",
       "\u001b[0;34m                a `tuple` is returned where the first element is the sample tensor.\u001b[0m\n",
       "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# By default samples have to be AT least a multiple of the overall upsampling factor.\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# The overall upsampling factor is equal to 2 ** (# num of upsampling layers).\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# However, the upsampling interpolation output size can be forced to fit any upsampling size\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# on the fly if necessary.\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mdefault_overall_up_factor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_upsamplers\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# upsample size should be forwarded when sample is not a multiple of `default_overall_up_factor`\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mforward_upsample_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mupsample_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdefault_overall_up_factor\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Forward upsample size to force interpolation output size.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mforward_upsample_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# ensure attention_mask is a bias, and give it a singleton query_tokens dimension\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# expects mask of shape:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m#   [batch, key_tokens]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# adds singleton query_tokens dimension:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m#   [batch,                    1, key_tokens]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# this helps to broadcast it as a bias over attention scores, which will be in one of the following shapes:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m#   [batch,  heads, query_tokens, key_tokens] (e.g. torch sdp attn)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m#   [batch * heads, query_tokens, key_tokens] (e.g. xformers or classic attn)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mattention_mask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;31m# assume that mask is expressed as:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;31m#   (1 = keep,      0 = discard)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;31m# convert mask into a bias that can be added to attention scores:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;31m#       (keep = +0,     discard = -10000.0)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m10000.0\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# convert encoder_attention_mask to a bias the same way we do for attention_mask\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mencoder_attention_mask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mencoder_attention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m10000.0\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mencoder_attention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# 0. center input if necessary\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcenter_input_sample\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msample\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# 1. time\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mtimesteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimestep\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimesteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;31m# TODO: this requires sync between CPU and GPU. So try to pass timesteps as tensors if you can\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;31m# This would be a good case for the `match` statement (Python 3.10+)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mis_mps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"mps\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimestep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_mps\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_mps\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mtimesteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtimesteps\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimesteps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mtimesteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimesteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# broadcast to batch dimension in a way that's compatible with ONNX/Core ML\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mtimesteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimesteps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mt_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimesteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# `Timesteps` does not contain any weights and will always return f32 tensors\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# but time_embedding might actually be running in fp16. so we need to cast here.\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# there might be better ways to encapsulate this.\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mt_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt_emb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0memb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimestep_cond\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0maug_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_embedding\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mclass_labels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"class_labels should be provided when num_class_embeds > 0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_embed_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"timestep\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mclass_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;31m# `Timesteps` does not contain any weights and will always return f32 tensors\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;31m# there might be better ways to encapsulate this.\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mclass_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclass_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mclass_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_embeddings_concat\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0memb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_emb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0memb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0memb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mclass_emb\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddition_embed_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"text\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0maug_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddition_embed_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"text_image\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;31m# Kandinsky 2.1 - style\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0;34m\"image_embeds\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0madded_cond_kwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0;34mf\"{self.__class__} has the config param `addition_embed_type` set to 'text_image' which requires the keyword argument `image_embeds` to be passed in `added_cond_kwargs`\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mimage_embs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madded_cond_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"image_embeds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mtext_embs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madded_cond_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"text_embeds\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0maug_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_embs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_embs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddition_embed_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"text_time\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0;34m\"text_embeds\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0madded_cond_kwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0;34mf\"{self.__class__} has the config param `addition_embed_type` set to 'text_time' which requires the keyword argument `text_embeds` to be passed in `added_cond_kwargs`\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mtext_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madded_cond_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"text_embeds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0;34m\"time_ids\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0madded_cond_kwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0;34mf\"{self.__class__} has the config param `addition_embed_type` set to 'text_time' which requires the keyword argument `time_ids` to be passed in `added_cond_kwargs`\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mtime_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madded_cond_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"time_ids\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mtime_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_time_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mtime_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime_embeds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_embeds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0madd_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtext_embeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_embeds\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0madd_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_embeds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0maug_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madd_embeds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddition_embed_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"image\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;31m# Kandinsky 2.2 - style\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0;34m\"image_embeds\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0madded_cond_kwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0;34mf\"{self.__class__} has the config param `addition_embed_type` set to 'image' which requires the keyword argument `image_embeds` to be passed in `added_cond_kwargs`\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mimage_embs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madded_cond_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"image_embeds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0maug_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_embs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddition_embed_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"image_hint\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;31m# Kandinsky 2.2 - style\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0;34m\"image_embeds\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0madded_cond_kwargs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"hint\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0madded_cond_kwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0;34mf\"{self.__class__} has the config param `addition_embed_type` set to 'image_hint' which requires the keyword arguments `image_embeds` and `hint` to be passed in `added_cond_kwargs`\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mimage_embs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madded_cond_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"image_embeds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mhint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madded_cond_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"hint\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0maug_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_embs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0memb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0memb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0maug_emb\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0maug_emb\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0memb\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime_embed_act\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0memb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime_embed_act\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder_hid_proj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder_hid_dim_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"text_proj\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mencoder_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder_hid_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder_hid_proj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder_hid_dim_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"text_image_proj\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;31m# Kadinsky 2.1 - style\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0;34m\"image_embeds\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0madded_cond_kwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0;34mf\"{self.__class__} has the config param `encoder_hid_dim_type` set to 'text_image_proj' which requires the keyword argument `image_embeds` to be passed in  `added_conditions`\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mimage_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madded_cond_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"image_embeds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mencoder_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder_hid_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_embeds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder_hid_proj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder_hid_dim_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"image_proj\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;31m# Kandinsky 2.2 - style\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0;34m\"image_embeds\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0madded_cond_kwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0;34mf\"{self.__class__} has the config param `encoder_hid_dim_type` set to 'image_proj' which requires the keyword argument `image_embeds` to be passed in  `added_conditions`\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mimage_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madded_cond_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"image_embeds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mencoder_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder_hid_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_embeds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# 2. pre-process\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_in\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# 3. down\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mdown_block_res_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mfor\u001b[0m \u001b[0mdownsample_block\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdown_blocks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdownsample_block\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"has_cross_attention\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdownsample_block\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_cross_attention\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownsample_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0mhidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0mtemb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0mcross_attention_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcross_attention_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownsample_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mdown_block_res_samples\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mres_samples\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mdown_block_additional_residuals\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mnew_down_block_res_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mfor\u001b[0m \u001b[0mdown_block_res_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdown_block_additional_residual\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mdown_block_res_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdown_block_additional_residuals\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mdown_block_res_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdown_block_res_sample\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdown_block_additional_residual\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mnew_down_block_res_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_down_block_res_samples\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdown_block_res_sample\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mdown_block_res_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_down_block_res_samples\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# 4. mid\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmid_block\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmid_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0memb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mcross_attention_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcross_attention_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mmid_block_additional_residual\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmid_block_additional_residual\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# 5. up\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupsample_block\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mup_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mis_final_block\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mup_blocks\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mres_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdown_block_res_samples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupsample_block\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresnets\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mdown_block_res_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdown_block_res_samples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupsample_block\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresnets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;31m# if we have not reached the final block and need to forward the\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;31m# upsample size, we do it here\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_final_block\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mforward_upsample_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mupsample_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdown_block_res_samples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupsample_block\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"has_cross_attention\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mupsample_block\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_cross_attention\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupsample_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0mhidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0mtemb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0mres_hidden_states_tuple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0mcross_attention_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcross_attention_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0mupsample_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupsample_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupsample_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0mhidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_hidden_states_tuple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupsample_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupsample_size\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# 6. post-process\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_norm_out\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_norm_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_act\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mUNet2DConditionOutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mInit docstring:\u001b[0m Initialize internal Module state, shared by both nn.Module and ScriptModule."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9802580b-69b8-4425-a4a1-157782508814",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
